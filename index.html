<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="View-consistent Object Removal in Radiance Fields.">
    <meta name="keywords" content="Multiview Segmentation, Neural Radiance Fields, 3D Editing">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Segment-then-Splat</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>
<body>

<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Segment-then-Splat: A Unified Approach for 3D Open-Vocabulary Segmentation based on Gaussian Splatting</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yiren-lu.com/" target="_blank">Yiren Lu</a>,</span>
                <span class="author-block">
                  <a href="https://github.com/Allen-Zhou729" target="_blank">Yunlai Zhou</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=XdvVFb0AAAAJ&hl=en" target="_blank">Yiran Qiao</a>,</span>
                <span class="author-block">
                  <a href="https://ieeexplore.ieee.org/author/37088982175" target="_blank">Chaoda Song</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=YBKC-AoAAAAJ&hl=en" target="_blank">Tuo Liang</a>,</span>
                <span class="author-block">
                  <a href="https://jma712.github.io/" target="_blank">Jing Ma</a>,</span>
                <span class="author-block">
                  <a href="https://yin-yu.github.io/" target="_blank">Yu Yin</a>
                </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Case Western Reserve University</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2408.02100v1.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2408.02100v1" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming soon)</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Abstract</h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/2d_vs_3d.png" alt="MY ALT TEXT"/>
      </div>
      <div class="content has-text-justified">
        <p>
          Open-vocabulary querying in 3D space is crucial for enabling more intelligent perception in applications such as robotics, autonomous systems, and augmented reality. However, most existing methods rely on 2D pixel-level parsing, leading to multi-view inconsistencies and poor 3D object retrieval. Moreover, they are limited to static scenes and struggle with dynamic scenes due to the complexities of motion modeling.
          In this paper, we propose <em><b>Segment then Splat</b></em>, a 3D-aware open vocabulary segmentation approach for both static and dynamic scenes based on Gaussian Splatting. 
          <em><b>Segment then Splat</b></em> reverses the long established approach of ``segmentation after reconstruction" by dividing Gaussians into distinct object sets before reconstruction. Once the reconstruction is complete, the scene is naturally segmented into individual objects, achieving true 3D segmentation. This approach not only eliminates Gaussian-object misalignment issues in dynamic scenes but also accelerates the optimization process, as it eliminates the need for learning a separate language field.
          After optimization, a CLIP embedding is assigned to each object to enable open-vocabulary querying. Extensive experiments on various datasets demonstrate the effectiveness of our proposed method in both static and dynamic scenarios.
        </p>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- pipeline overview -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Pipeline Overview</h2>
      </div>
      <div class="item">
        <img src="static/images/framework.png" alt="MY ALT TEXT"/>
      </div>
      <div class="content has-text-justified">
        <p>
          <b>A detailed demonstration of our proposed Segment then Splat pipeline.</b> Our approach first extracts multi-view masks for each object through a robust tracking module, then object IDs are assigned to each initial Gaussian based on these masks, forming distinct object-specific sets. During optimization, object specific loss \(\mathcal{L}_{\text{obj}}\) is used to enforce Gaussian-object correspondence and thus resulting in more accurate object geometries. Finally, we associate each Gaussian group with CLIP embeddings, enabling open-vocabulary queries.
        </p>
    </div>
  </div>
</section>
<!-- End pipeline overview -->

<section class="hero is-small">
    <div class="hero-body">
        <div class="container has-text-centered">
            <h2 class="title">Scene Object Removal Results</h2>
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item rounded-0 border-0 item-1">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/ori_1_spiral_050000_rgb.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/1_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item rounded-0 border-0 item-2">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/ori_2_spiral_050000_rgb.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/2_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item rounded-0 border-0 item-3">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/ori_3_spiral_050000_rgb.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/3_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item rounded-0 border-0 item-4">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/ori_4_spiral_050000_rgb.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/4_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item rounded-0 border-0 item-7">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/ori_7_spiral_050000_rgb.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/7_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item rounded-0 border-0 item-9">
                  <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                      <source src="static/videos/ori_9_spiral_050000_rgb.mp4" type="video/mp4">
                  </video>
                  <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                      <source src="static/videos/9_removed_gs.mp4" type="video/mp4">
                  </video>
              </div>
                <div class="item rounded-0 border-0 item-10">
                  <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                      <source src="static/videos/ori_10_spiral_050000_rgb.mp4" type="video/mp4">
                  </video>
                  <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                      <source src="static/videos/10_removed_gs.mp4" type="video/mp4">
                  </video>
              </div>
                <div class="item rounded-0 border-0 item-12">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/12_ori.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/12_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item rounded-0 border-0 item-book">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/ori_book_spiral_050000_rgb.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/book_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item rounded-0 border-0 item-trash">
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/ori_trash_spiral_050000_rgb.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay muted loop preload="none" class="w-auto" style="height:22vh;">
                        <source src="static/videos/trash_removed_gs.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </div>
</section>
<br/>

<section class="hero teaser">
    <div class="container is-max-desktop has-text-centered shadow-sm">
        <br/>
        <h2 class="title">Comparison with Previous Methods</h2>
        <div class="row">
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/ori_3_spiral_050000_rgb.mp4"
                            type="video/mp4">
                </video>
            </div>
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/3_lpips_True_prepare_False_010000_rgb.mp4"
                            type="video/mp4">
                </video>
            </div>
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/3_nerfiller.mp4"
                            type="video/mp4">
                </video>
            </div>
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/3_removed_gs.mp4"
                            type="video/mp4">
                </video>
            </div>
        </div>
        <div class="row">
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/ori_book_spiral_050000_rgb.mp4"
                            type="video/mp4">
                </video>
                <h5 class="subtitle">Original Scene</h5>
            </div>
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/book_lpips_True_prepare_False_010000_rgb.mp4"
                            type="video/mp4">
                </video>
                <h5 class="subtitle">SPIn-NeRF</h5>
            </div>
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/book_nerfiller.mp4"
                            type="video/mp4">
                </video>
                <h5 class="subtitle">NeRFiller</h5>
            </div>
            <div class="col-3">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                    <source src="static/videos/book_removed_gs.mp4"
                            type="video/mp4">
                </video>
                <h5 class="subtitle">Ours</h5>
            </div>
        </div>
    </div>
</section>
<br/>

<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="column is-centered ">
        <h2 class="title has-text-centered">Multi-view Consistency</h2>
          <div class="row d-flex justify-content-around">
            <div class="content has-text-justified">
              <p class="content">Here we showcase how our pipeline ensures the multi-view consistency by evaluating the number of keypoint matchings across different rendered views. These keypoint matchings are given by SuperGlue, and we only consider the matchings within the inpainted region. As evident in the results, our pipeline has significantly more results within the inpainted region, which indicates a better multi-view consistency.</p>
            </div>
            <div class="row justify-content-around">
              <div class="col-8">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                <source src="static/videos/book_spinnerf_matching.mp4"
                        type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">SPIn-NeRF</h2>
              </div>
            </div>
            <div class="row justify-content-around">
              <div class="col-8">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                <source src="static/videos/book_nerfiller_matching.mp4"
                        type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">NeRFiller</h2>
              </div>
            </div>
            <div class="row justify-content-around">
              <div class="col-8">
                <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                <source src="static/videos/book_gs_matching.mp4"
                        type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">Ours</h2>
              </div>
            </div>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="column is-full">
        <h2 class="title has-text-centered">Mask Consistency</h2>
          <div class="row d-flex justify-content-around">
            <div class="content has-text-justified">
              <p class="content has-text-justified">Our multi-view segmentation approach can not only maintain mask consistency across different views, but can also take regions without semantic meanings into consideration (i.e. the shadow on the left side of the book).
              </p>
            </div>
            <div class="col-5 p-1">
              <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                <source src="static/videos/ori_book_spiral_050000_rgb.mp4"
                        type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered">Original Scene</h2>
            </div>
            <div class="col-5 p-1">
              <video poster="" autoplay muted loop height="100%" class="rounded" preload="none">
                <source src="static/videos/book_mask.mp4"
                        type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered">Masks</h2>
            </div>
          </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">Citation</h2>
        <p>If you find our work helpful, please consider cite us:</p>
        <pre><code>@misc{lu2024viewconsistentobjectremovalradiance,
          title={View-consistent Object Removal in Radiance Fields}, 
          author={Yiren Lu and Jing Ma and Yu Yin},
          year={2024},
          eprint={2408.02100},
          archivePrefix={arXiv},
          primaryClass={cs.CV},
          url={https://arxiv.org/abs/2408.02100}, 
    }
</code></pre>
    </div>
</section>


<footer class="footer">
  <div class="container">
      <div class="columns is-centered">
          <div class="column is-8">
              <div class="content">
                  <p>Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.</p>
                  <p>
                      This website is licensed under a <a rel="license"
                                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                      Commons Attribution-ShareAlike 4.0 International License</a>.
                  </p>
                  <p>
                      This means you are free to borrow the <a
                          href="https://github.com/vulab-AI/Segment-then-Splat">source code</a> of this website,
                      we just ask that you link back to this page in the footer.
                      Please remember to remove the analytics code included in the header of the website which
                      you do not want on your website.
                  </p>
              </div>
          </div>
      </div>
  </div>
</footer>

</body>
</html>
